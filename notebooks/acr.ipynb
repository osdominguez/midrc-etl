{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import chain\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSIONS = [\n",
    "    \"acrimage/2021/06\",\n",
    "    \"acrimage/2021/07\",\n",
    "    \"acrimage/2021/08\",\n",
    "    \"acrimage/2021/0827\",  # fu\n",
    "    \"acrimage/2021/09\",\n",
    "    \"acrimage/2021/10/batch6\",\n",
    "    \"acrimage/2021/10/batch7\",\n",
    "    \"acrimage/2021/11\",\n",
    "    \"acrimage/2021/ACRPETAL_20211220\",\n",
    "    \"acrimage/2022/ACR_20220107\",\n",
    "    \"ACR_20211115\",\n",
    "    \"ACR_20220107\",\n",
    "    \"ACR_20220218\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION = SUBMISSIONS[3]\n",
    "SUBMISSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGES_PATH = Path(\n",
    "    f\"/Users/andrewprokhorenkov/CTDS/projects/midrc/indexing-data/packages_acr/packages_{SUBMISSION}\"\n",
    ")\n",
    "PACKAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RSNA_PATH = Path(\"/Users/andrewprokhorenkov/CTDS/projects/midrc/processed-s3\")\n",
    "SUBMISSION_PATH = RSNA_PATH / SUBMISSION\n",
    "\n",
    "image_manifest_file = list(\n",
    "    chain(\n",
    "        SUBMISSION_PATH.glob(\"**/CIRR*.txt\"),\n",
    "        SUBMISSION_PATH.glob(\"**/*image_manifest*.txt\"),\n",
    "        SUBMISSION_PATH.glob(\"**/image_*.txt\"),\n",
    "        SUBMISSION_PATH.glob(\"image_*.tsv\"),\n",
    "        SUBMISSION_PATH.glob(\"*_instance_*.tsv\"),\n",
    "    )\n",
    ")\n",
    "# studies_file = list(SUBMISSION_PATH.glob(\"*imaging_study_*.tsv\"))[0]\n",
    "series_files = list(\n",
    "    chain(\n",
    "        SUBMISSION_PATH.glob(\"**/*_series_*.txt\"),\n",
    "        SUBMISSION_PATH.glob(\"*_series_*.tsv\"),\n",
    "    )\n",
    ")\n",
    "# instance_files = list(SUBMISSION_PATH.glob(\"*_instance_*.tsv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    \"case_ids\": \"case_id\",\n",
    "    \"Subject_ID\": \"case_id\",\n",
    "    \"series_uid\": \"series_id\",\n",
    "    \"dr_exams.submitter_id\": \"study_id\",\n",
    "    \"radiography_exam.submitter_id\": \"study_id\",\n",
    "    \"radiography_exams.submitter_id\": \"study_id\",\n",
    "    \"ct_scan.submitter_id\": \"study_id\",\n",
    "    \"ct_scans.submitter_id\": \"study_id\",\n",
    "    \"mr_exams.submitter_id\": \"study_id\",\n",
    "    \"nm_exams.submitter_id\": \"study_id\",\n",
    "    \"pt_scans.submitter_id\": \"study_id\",\n",
    "    \"pr_exams.submitter_id\": \"study_id\",\n",
    "    \"rf_exams.submitter_id\": \"study_id\",\n",
    "    \"series-submitter\": \"submitter_id\",\n",
    "}\n",
    "\n",
    "series = map(\n",
    "    lambda v: pd.read_csv(v, sep=\"\\t\").rename(columns=rename_columns), series_files\n",
    ")\n",
    "series = pd.concat(series, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# series[\"study_id\"] = series[\"study_id\"].apply(lambda v: v.split(\"_\")[1])\n",
    "\n",
    "series = series[[\"series_id\", \"study_id\", \"case_id\"]].drop_duplicates()\n",
    "\n",
    "series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    \"case_ids\": \"case_id\",\n",
    "    \"study_uid\": \"study_id\",\n",
    "    \"ct_scans.submitter_id\": \"study_id\",\n",
    "    \"radiography_exam.submitter_id\": \"study_id\",\n",
    "    \"series_uid\": \"series_id\",\n",
    "    \"series.submitter_id\": \"series_id\",\n",
    "    \"cr_series.submitter_id\": \"series_id\",\n",
    "    \"ct_series.submitter_id\": \"series_id\",\n",
    "    \"dx_series.submitter_id\": \"series_id\",\n",
    "    \"*md5sum\": \"md5sum\",\n",
    "    \"mdsum\": \"md5sum\",\n",
    "    \"*file_name\": \"file_name\",\n",
    "    \"*file_size\": \"file_size\",\n",
    "    \"submitter_id\": \"instance_id\",\n",
    "    \"object_id\": \"instance_id\",\n",
    "}\n",
    "\n",
    "instances = map(\n",
    "    lambda v: pd.read_csv(v, sep=\"\\t\").rename(columns=rename_columns),\n",
    "    image_manifest_file,\n",
    ")\n",
    "instances = pd.concat(instances, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# instances[\"series_id\"] = instances[\"series_id\"].apply(lambda v: v.split(\"_\")[1])\n",
    "# instances[\"study_id\"] = instances[\"study_id\"].apply(lambda v: v.split(\"_\")[1])\n",
    "\n",
    "instances = instances.merge(series, on=[\"case_id\", \"series_id\"])\n",
    "\n",
    "if instances[\"file_size\"].dtype == np.dtype(\"O\"):\n",
    "    instances[\"file_size\"] = instances[\"file_size\"].apply(lambda v: locale.atoi(v))\n",
    "instances = instances[\n",
    "    [\n",
    "        \"file_name\",\n",
    "        \"file_size\",\n",
    "        \"md5sum\",\n",
    "        \"case_id\",\n",
    "        \"study_id\",\n",
    "        \"series_id\",\n",
    "        \"instance_id\",\n",
    "        \"storage_urls\",\n",
    "    ]\n",
    "].drop_duplicates()\n",
    "\n",
    "# instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_packages = []\n",
    "\n",
    "for i, row in instances.iterrows():\n",
    "    case_id = row[\"case_id\"]\n",
    "    study_id = row[\"study_id\"]\n",
    "    series_id = row[\"series_id\"]\n",
    "\n",
    "    series_path = f\"./cases/{case_id}/{study_id}/{series_id}.tsv\\n\"\n",
    "    if series_path not in list_of_packages:\n",
    "        list_of_packages.append(series_path)\n",
    "\n",
    "    # print(f\"{case_id} / {study_id}\")\n",
    "\n",
    "    folder = PACKAGES_PATH / \"cases\" / case_id / study_id\n",
    "\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    series_file = folder / f\"{series_id}.tsv\"\n",
    "    series_file_exist = series_file.exists()\n",
    "\n",
    "    with open(series_file, mode=\"a\") as f:\n",
    "        fieldnames = [\n",
    "            \"file_name\",\n",
    "            \"file_size\",\n",
    "            \"md5sum\",\n",
    "            \"case_id\",\n",
    "            \"study_id\",\n",
    "            \"series_id\",\n",
    "            \"instance_id\",\n",
    "            \"storage_urls\",\n",
    "        ]\n",
    "        writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=fieldnames)\n",
    "\n",
    "        if not series_file_exist:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row.to_dict())\n",
    "\n",
    "with open(PACKAGES_PATH / \"packages.txt\", \"w\") as f:\n",
    "    f.writelines(list_of_packages)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4788fb3d406e5627ce93ce2328ec2a20d72350bcb84a0da657cf44b605da6122"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
