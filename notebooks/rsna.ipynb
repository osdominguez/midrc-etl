{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSIONS = [\n",
    "    # \"midrc-ricord-2021-08-20\",\n",
    "    \"midrc-ricord-2021-09-02\",\n",
    "    \"midrc-ricord-2021-09-22\",\n",
    "    \"midrc-ricord-2021-10-06\",\n",
    "    \"midrc-ricord-2021-10-26\",\n",
    "    \"RSNA_20211117\",\n",
    "    \"RSNA_20211214\",\n",
    "    \"RSNA_20220105\",\n",
    "    \"RSNA_20220114\",\n",
    "    \"RSNA_20220124\",\n",
    "    \"RSNA_20220211\",\n",
    "    \"RSNA_20220214\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_submission(SUBMISSION):\n",
    "    # useful paths for data manipulation\n",
    "    print(SUBMISSION)\n",
    "    PACKAGES_PATH = Path(f\"/Users/andrewprokhorenkov/CTDS/projects/midrc/midrc_indexing_scripts/packages/packages_{SUBMISSION}\")\n",
    "    PACKAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    RSNA_PATH = Path(\"/Users/andrewprokhorenkov/CTDS/projects/midrc/s3-data/raw/rsna\")\n",
    "    SUBMISSION_PATH = RSNA_PATH / SUBMISSION\n",
    "\n",
    "    # get all the necessary files\n",
    "\n",
    "    image_manifest_file = list(SUBMISSION_PATH.glob(\"imaging_data_manifest_*.tsv\"))[0]\n",
    "    studies_file = list(SUBMISSION_PATH.glob(\"*imaging_study_*.tsv\"))[0]\n",
    "    series_files = list(SUBMISSION_PATH.glob(\"*_series_*.tsv\"))\n",
    "    instance_files = list(SUBMISSION_PATH.glob(\"*_instance_*.tsv\"))\n",
    "\n",
    "    # instance_files = list(SUBMISSION_PATH.glob(\"midrc_*_instance_*.tsv\"))\n",
    "    # instance_files = list(SUBMISSION_PATH.glob(\"midrc_*_image_*.tsv\"))\n",
    "    # studies_file = list(SUBMISSION_PATH.glob(\"midrc_imaging_study_*.tsv\"))[0]\n",
    "\n",
    "    id_pattern = r\"([\\d\\.]+)$\"\n",
    "    id_regex = re.compile(id_pattern)\n",
    "\n",
    "    # load all files into pandas DF's\n",
    "\n",
    "    image_manifest = pd.read_csv(image_manifest_file, sep=\"\\t\")\n",
    "\n",
    "    studies = pd.read_csv(studies_file, sep=\"\\t\")\n",
    "\n",
    "    rename_columns_studies = {\n",
    "        \"cases.submitter_id\": \"case_id\",\n",
    "        \"cases\": \"case_id\", # for \"midrc-ricord-2021-08-20\"\n",
    "        \"study_uid\": \"study_id\",\n",
    "    }\n",
    "\n",
    "    studies = studies.rename(columns=rename_columns_studies)\n",
    "\n",
    "    studies[\"case_id\"] = studies[\"case_id\"].apply(lambda v: v.removeprefix(\"Case_\"))\n",
    "\n",
    "    studies = studies[[\"study_id\", \"case_id\"]]\n",
    "    \n",
    "    series = list(map(lambda v: pd.read_csv(v, sep=\"\\t\"), series_files))\n",
    "\n",
    "    rename_columns_series = {\n",
    "        \"mr_exams.submitter_id\": \"study_id\",\n",
    "        \"ct_scans.submitter_id\": \"study_id\",\n",
    "        \"radiography_exams.submitter_id\": \"study_id\",\n",
    "        \"case_ids\": \"case_id\",\n",
    "        \"series_uid\": \"series_id\",\n",
    "    }\n",
    "\n",
    "    series = list(\n",
    "        map(\n",
    "            lambda v: v.rename(columns=rename_columns_series)[\n",
    "                [\"series_id\", \"study_id\", \"case_id\"]\n",
    "            ],\n",
    "            series,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    all_series = pd.concat(series)\n",
    "    all_series[\"case_id\"] = all_series[\"case_id\"].apply(lambda v: v.removeprefix(\"Case_\"))\n",
    "    all_series[\"study_id\"] = all_series[\"study_id\"].apply(lambda v: id_regex.search(v).group(0))\n",
    "\n",
    "    instances = list(map(lambda v: pd.read_csv(v, sep=\"\\t\"), instance_files))\n",
    "\n",
    "    rename_columns_instances = {\n",
    "        \"cr_series.submitter_id\": \"series_id\",\n",
    "        \"dx_series.submitter_id\": \"series_id\",\n",
    "        \"ct_series.submitter_id\": \"series_id\",\n",
    "        \"mr_series.submitter_id\": \"series_id\",\n",
    "        \"submitter_id\": \"instance_id\",\n",
    "        \"case_ids\": \"case_id\",\n",
    "    }\n",
    "\n",
    "    instances = list(map(lambda v: v.rename(columns=rename_columns_instances), instances))\n",
    "\n",
    "    all_instances = pd.concat(instances)\n",
    "    all_instances[\"case_id\"] = all_instances[\"case_id\"].apply(lambda v: v.removeprefix(\"Case_\"))\n",
    "    all_instances[\"instance_id\"] = all_instances[\"instance_id\"].apply(lambda v: id_regex.search(v).group(0))\n",
    "    all_instances[\"series_id\"] = all_instances[\"series_id\"].apply(lambda v: id_regex.search(v).group(0))\n",
    "\n",
    "    all_instances = all_instances[[\"instance_id\", \"series_id\", \"case_id\", \"file_name\", \"file_size\", \"md5sum\", \"storage_urls\"]]\n",
    "\n",
    "    merged = image_manifest.merge(all_instances).merge(all_series).merge(studies)\n",
    "    merged[\"file_name\"] = merged[\"instance_id\"].apply(lambda v: f\"{v}.dcm\")\n",
    "    merged = merged[[\"file_name\", \"file_size\", \"md5sum\", \"storage_urls\", \"case_id\", \"study_id\", \"series_id\"]]\n",
    "\n",
    "    print(f\"{image_manifest.shape}\\n{merged.shape}\")\n",
    "\n",
    "    list_of_packages = []\n",
    "\n",
    "    for i, row in merged.iterrows():\n",
    "        case_id = row[\"case_id\"]\n",
    "        study_id = row[\"study_id\"]\n",
    "        series_id = row[\"series_id\"]\n",
    "\n",
    "        series_path = f\"./cases/{case_id}/{study_id}/{series_id}.tsv\\n\"\n",
    "        if series_path not in list_of_packages:\n",
    "            list_of_packages.append(series_path)\n",
    "\n",
    "        folder = PACKAGES_PATH / \"cases\" / case_id / study_id\n",
    "\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        series_file = folder / f\"{series_id}.tsv\"\n",
    "        series_file_exist = series_file.exists()\n",
    "\n",
    "        with open(series_file, mode=\"a\") as f:\n",
    "            fieldnames = [\"file_name\", \"file_size\", \"md5sum\", \"case_id\", \"study_id\", \"series_id\", \"instance_id\", \"storage_urls\"]\n",
    "            writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=fieldnames)\n",
    "\n",
    "            if not series_file_exist:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(row.to_dict())\n",
    "\n",
    "    with open(PACKAGES_PATH / \"packages.txt\", \"w\") as f:\n",
    "        f.writelines(list_of_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SUBMISSION in SUBMISSIONS:\n",
    "    process_submission(SUBMISSION)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4788fb3d406e5627ce93ce2328ec2a20d72350bcb84a0da657cf44b605da6122"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
